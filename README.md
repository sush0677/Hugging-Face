# Hugging Face Deep Reinforcement Learning Models

This repository contains the machine learning models I’ve developed and saved, with a focus on **Deep Reinforcement Learning (DRL)**, built while learning from **Hugging Face**'s extensive tutorials and resources. These models are created using various DRL algorithms and frameworks, leveraging the power of Hugging Face’s ecosystem for sharing, training, and deploying models.

## Models Overview:
- **Deep Reinforcement Learning Models**: The models in this repository are trained using popular DRL algorithms such as **Proximal Policy Optimization (PPO)**, **Deep Q-Networks (DQN)**, and others, depending on the task at hand.
- **Hugging Face Integration**: These models are stored, shared, and made accessible through **[My Hugging Face Model Repository](your-hugging-face-repo-link)**, allowing for easy deployment, collaboration, and exploration of the results.

### Key Features:
- **Custom Implementations**: Each model comes with custom implementations and tweaks based on my learning from Hugging Face.
- **Performance Metrics**: The models include training logs, evaluation results, and hyperparameter configurations to track performance improvements.
- **Pre-trained Models**: Some models are pre-trained and available for further fine-tuning or immediate deployment.

### Repository Structure:
- `models/`: Contains the saved models with all necessary files.
- `notebooks/`: Jupyter notebooks showcasing the training, evaluation, and usage of the models.
- `scripts/`: Python scripts to reproduce the results, including custom DRL training routines.
- `huggingface/`: Integration files with Hugging Face, enabling easy access to models via the Hugging Face Model Hub.

Explore my Hugging Face repository for further details on the models and their usage: **https://huggingface.co/Sush0677/ppo-LunarLander-v2**.

